Analysis of Sorting Algorithms in relation to time complexities:
As discussed in class, the time complexities for InsertionSort, QuickSort, and MergeSort are O(n^2), O(n^2), and O(nlogn), respectively. As n increases, the differences between these complexities become pronounced. One can see this in the difference of sorting short (n <= 10) lists. From sorting one such array (WordList), the duration of MergeSort is actually not even the shortest sorting algorithm. This could happen because of the initial order of the array. As the array seems to be randomly generated, one can not state that the sorting algorithms do not follow their specified time complexities. This is because there is simply not enough evidence to prove that claim. To do so, one must sort multiple arrays of varying order to better see the pattern. Similarly, the time complexities stated before are WORST CASE complexities. As such, the provided arrays might not be ordered to fit each algorithm's worst case scenario. 

As mentioned before, once the provided array becomes larger, the proportionalities of each algorithm's time complexity begins to affect the sorting time. Interestingly, once the (n >= 10000) list is sorted, one notices that the QuickSort algorithm actually performs worse than InsertionSort. This is unusual as average performance of QuickSort is O(nlogn) compared to InsertionSort's O(n^2). However, the hiccup actually fits with the previous point stating that the provided list might have just been ordered in such a way that it better fits the ordering for QuickSort's worst case scenario than InsertionSort's worst case scenario.